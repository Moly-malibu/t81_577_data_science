{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Neural Network \n",
    "\n",
    "I highly recommend you to go to [this](http://neuralnetworksanddeeplearning.com/) awesome site  or take deep learning specialization in coursera from Andrew Ng if you want to learn more about neural network.\n",
    "\n",
    "Consider a problem when you need to build a model to predict housing prices based upon four features: size, number of bedrooms, zipcode, and wealth. Think of some useful features that you could possibly engineer based upon those information as shown in the figure below. Probably, you could create a feature related to family size that a given house can accommodate by combining information from the house size and the number of beds. You might create a feature that holds the information related to walkability in the community based upon zipcode information. Similarly, you might create another feature that possibly informs on nearby school quality. Then you can combine those additional features with the original data set to build a final predictive model. Essentially, you are hand-crafting the feature engineering process based upon your heuristics. The main intuition in neural network modelling is that you just provide the original input and output features, and the neural network creates intermediary information on your behalf that could be useful for the model. You just need to specify in the beginning the number of such intermediary information (layer and neurons) that the model needs to include and let the neural network learn the representation based upon the examples of houses with various prices and features.\n",
    "\n",
    "![](../files/neural-house.png)\n",
    "\n",
    "Recall the following concepts from logistic regression from [last week] lecture.\n",
    "\n",
    "- Sigmoid function <br>\n",
    "- Logloss funtiion, \n",
    "\n",
    "Logistic regression can be thought of as a two-step computation process. In the first step, the features x and parameters w and b are used to compute z, which are then passed to a sigmoid unit in the second step to compute y hat. You can then compute the loss function using the true y and yhat from model output. \n",
    "\n",
    "![](../files/logistic.png)\n",
    "\n",
    "You can create a neural network by stacking up many such sigmoid units in intermediate layers between input and output layers. The input layer is similar to logistic regression. The information from these input layers are then passed into intermediary units with different combinations of weight and bias parameters. Each sigmoid unit will output `activation`, which can be further combined to compute the output function. \n",
    "\n",
    "![](../files/neural.png)\n",
    "\n",
    "In the simple neural network above, there is only one intermediate layer, which is known as a hidden layer. Complex networks can contain many hidden layers. Each sigmoid unit is called neuron (or node), and a single hidden layer can potentially have any number of neurons. The design of the input and output layers of a neural network is often straightforward based upon the number of input features, whereas, the design of the hidden layers can take quite an art.\n",
    "\n",
    "Neural network learns in a similar fashion as logistic regression i.e. it tries to compute model parameters that minimizes cost function. However, there are many parameters associated with neurons in the hidden and output layers that need to be simultaneously estimated. And since they are interconnected, the slight change in values of a parameter in a neuron affect others, and hence weight and bias updating could be a daunting task. Neural network solves this problem using a technique called backpropagation to  train a network through a method is calculus called chain rule. Go [here](https://towardsdatascience.com/understanding-backpropagation-algorithm-7bb3aa2f95fd) to learn how backpropagation works.  \n",
    "\n",
    "The output at each neuron is the activation of a weighted sum of inputs to the neuron. The activation we discussed is the sigmoid function. There are other different types of activations such as `Tanh` and `ReLu`, which are much more widely used than sigmoid. \n",
    "\n",
    "There are a wide variety of neural networks out there; broadly they can be categorized into `feedforward` and `recurrent` neural networks. When the connections among the neurons are in the direction of input to the output layer i.e. where the output from one layer is used as input to the next layer, it is called feed forward neural network (network without any loop). When the connections are circular, it is called recurrent neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
