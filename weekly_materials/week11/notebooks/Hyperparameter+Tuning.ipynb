{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Hyperparameter?\n",
    "\n",
    "We briefly learned about the distinction between the terms parameters and hyperparameters in Week 9. To recap, the model parameters are the components of the model that are learned during the training of the model. The model parameters are required to make predictions from model. Examples of the model parameter include slope and coefficients of linear regression, and weights and biases in artificial neural network.\n",
    "\n",
    "In contrast to model parameters, hyperparameters relates to the architecture of your machine learning model. Hyperparameters cannot be directly learned during the training process and  often defined before model training. The hyperparameters determine the final parameters of the model.\n",
    "\n",
    "The process of searching for the best set of hyperparameter that leads to better model outcome is referred to as hyperparameter tuning/optimization.\n",
    "\n",
    "Let's take an example of random forest and find hyperparameters for random forest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "##create a simple random forest estimator using sklearn and print it out\n",
    "rf=RandomForestClassifier()\n",
    "print(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all configurations of a random forest model that we need to optimize to achive the best model performance. What do all these hyperparameter mean?The detailed description of each random forest hyperparameter is avaialble here: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html. \n",
    "\n",
    "Let's take an example:\n",
    "\n",
    "n_estimator: It is the number of trees in the forest. The default value is set to 10. Typically, the higher the number of trees leads to better performance. But this will also increase computation time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Let's check what are the hyperparameters of KNN Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "##create a simple knn estimator using sklearn and print it out\n",
    "knn=KNeighborsClassifier()\n",
    "print (knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are less number of hyperparameters for KNN than RF model. Go to scikit learn documentation page to learn more about hyperparameters for KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning/optimization\n",
    "\n",
    "As we saw in the random forest (RF) estimator, the RF model has many different hyperparameters we need to set. As the machine learning model becomes more complex, the number of hyperparameter we need to set also increases. The performance of a model highly depends on the choice of its hyperparameters. \n",
    "\n",
    "During the model training we don't know what the optimal set of hyperparamters should be for a given model, and thus we need to explore a range of possibilities. This process of exploring the set of optimal hyperparameters that improves model performance (reduced cost function) is referred to as hyperparameter tuning  or optimization. \n",
    " \n",
    "In general, a hyperparamter tuning/optimization includes the following steps:\n",
    "\n",
    "1. Define the model and possible sets of hyperparameters(not all the hyperprameters are important) and range of values for the selected hyperparameters\n",
    "2. Define the method for sampling of hyperparameter value\n",
    "2. Define the metric to be minimized or maximized for the problem in hand\n",
    "3. Split the data into training,validation and test sets\n",
    "4. Repeat the optimization loop a number of times over your sampled hyperparamter space:\n",
    "\n",
    "  (a) Select a new set of model hyperparameters   \n",
    "  (b) Train the model on the training subset using the selected set of hyperparameters  \n",
    "  (c) Apply the model to the test subset and generate the corresponding predictions  \n",
    "  (d) Evaluate the test predictions using the appropriate scoring metric for the problem at hand, such as accuracy or mean absolute error. Store the metric value that corresponds to the selected set of hyperparameters\n",
    "  \n",
    "3. Compare all metric values and choose the hyperparameter set that yields the best metric value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning methods\n",
    "\n",
    "As we know by now the hyperparameter tuning method includes \"searching\" the hyperparameter space for the optimum values. In general the hyperparameter tuning strategies can be grouped as:\n",
    "1. Manual search\n",
    "2. Grid Search\n",
    "3. Random Search\n",
    "4. Bayesian Optimization\n",
    "\n",
    "**Manual Search**\n",
    "\n",
    "In manual search, we initially choose a set of hyperparamters based upon heuristis. The model is trained with the sets of hyperparameters, scored on validation set and accuracy is assessed on test set. The process is repeated until a satisfactory result is obtained.The problem with such manual search is that the process could be highly computationally expensive. With each trial of search, we have to train a model on training data and evaluate the performance on validation data. This process can quickly become intractable with complex models with large number of hyperparameters such as deep learning model. \n",
    "\n",
    "**Grid Search**\n",
    "\n",
    "In grid search, we first set up a grid of hyperparameter values and the model is trained for each combination of hyperparamters and tested on the test set to find the optimal combination.  \n",
    "\n",
    "Let's take an exmple for random forest and consider the n_estimators and max_depth hyperparameters as below, which will result in total of thirty models\n",
    "\n",
    "n_estimators = [10, 50, 100, 200,500]  \n",
    "max_depth = [3, 10, 20, 40, 60, 100]\n",
    "\n",
    "Each model will be fit to the training data and evaluated on the validation data. Depending on the models, data size, grid search can often become computationally very expensive.\n",
    "\n",
    "**Random Search**\n",
    "\n",
    "In random search, we no longer provide a discrete set of values to explore the hyperparameter space. Instead, values for each hyperparameter is randomly sampled from a statistical distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main theoretical backings to motivate the use of random search in place of grid search is the fact that for most cases, hyperparameters are not equally important.\n",
    "\n",
    "*\"A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that **for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets**. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets.\"* - ***Bergstra, 2012*** \n",
    "\n",
    "During grid search, each hyperparameter is searched for the best possible value while holding all other hyperparameters constant. For cases where the hyperparameter being studied has little effect on the resulting model score, this results in wasted effort. Conversely, the random search has much improved exploratory power and can focus on finding the optimal value for the important hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesian Optimization**\n",
    "\n",
    "Both Grid Search and Random Search develops models from the set of parameters and record the performance of each model. However, each model is independent of the other and the information from previous models is not used to improve the next model. Bayesian optimization algorithm allows us to use the results of previous iterations when choosing hyperparameters set to evaluate in next iterations. By choosing the hyperparameters in an informed way, it limits the search of the parameter space and requires less iteration to get find the optimal set of hyperparameter values. Go [here](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f) to learn more about Bayesian optimization for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd  \n",
    "import seaborn as sns \n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    " \n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import (cross_val_score, train_test_split, \n",
    "                                     GridSearchCV, RandomizedSearchCV)\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## load the boston dataset from sklearn\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "## check what the boston dataset contains\n",
    "print(boston_dataset.keys())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the dataset characteristics for the Boston dataset.\n",
    "#print(boston_dataset.DESCR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prices of the house which is our target variable is in the attribute MEDV and remaining are our feature variable that we will use to predict the value of the house.\n",
    "\n",
    "***Pandas Dataframe Conversion***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert the data into a pandas dataframe and check the first 5 rows\n",
    "\n",
    "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston['MEDV'] = boston_dataset.target\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check if there are any missing values in the data frame\n",
    "boston.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       float64\n",
       "ZN         float64\n",
       "INDUS      float64\n",
       "CHAS       float64\n",
       "NOX        float64\n",
       "RM         float64\n",
       "AGE        float64\n",
       "DIS        float64\n",
       "RAD        float64\n",
       "TAX        float64\n",
       "PTRATIO    float64\n",
       "B          float64\n",
       "LSTAT      float64\n",
       "MEDV       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the data type of all the variables\n",
    "boston.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>CRIM</td>\n",
       "      <td>506.0</td>\n",
       "      <td>3.613524</td>\n",
       "      <td>8.601545</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.25651</td>\n",
       "      <td>3.677083</td>\n",
       "      <td>88.9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ZN</td>\n",
       "      <td>506.0</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INDUS</td>\n",
       "      <td>506.0</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.46000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>9.69000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>27.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CHAS</td>\n",
       "      <td>506.0</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NOX</td>\n",
       "      <td>506.0</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.38500</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>0.53800</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.8710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RM</td>\n",
       "      <td>506.0</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>3.56100</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>6.20850</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>8.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AGE</td>\n",
       "      <td>506.0</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.90000</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>77.50000</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DIS</td>\n",
       "      <td>506.0</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>1.12960</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>3.20745</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>12.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RAD</td>\n",
       "      <td>506.0</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TAX</td>\n",
       "      <td>506.0</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>187.00000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>330.00000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>711.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>506.0</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>12.60000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>19.05000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>22.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>506.0</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>0.32000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>391.44000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>396.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LSTAT</td>\n",
       "      <td>506.0</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>1.73000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>11.36000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>37.9700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MEDV</td>\n",
       "      <td>506.0</td>\n",
       "      <td>22.532806</td>\n",
       "      <td>9.197104</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>17.025000</td>\n",
       "      <td>21.20000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count        mean         std        min         25%        50%  \\\n",
       "CRIM     506.0    3.613524    8.601545    0.00632    0.082045    0.25651   \n",
       "ZN       506.0   11.363636   23.322453    0.00000    0.000000    0.00000   \n",
       "INDUS    506.0   11.136779    6.860353    0.46000    5.190000    9.69000   \n",
       "CHAS     506.0    0.069170    0.253994    0.00000    0.000000    0.00000   \n",
       "NOX      506.0    0.554695    0.115878    0.38500    0.449000    0.53800   \n",
       "RM       506.0    6.284634    0.702617    3.56100    5.885500    6.20850   \n",
       "AGE      506.0   68.574901   28.148861    2.90000   45.025000   77.50000   \n",
       "DIS      506.0    3.795043    2.105710    1.12960    2.100175    3.20745   \n",
       "RAD      506.0    9.549407    8.707259    1.00000    4.000000    5.00000   \n",
       "TAX      506.0  408.237154  168.537116  187.00000  279.000000  330.00000   \n",
       "PTRATIO  506.0   18.455534    2.164946   12.60000   17.400000   19.05000   \n",
       "B        506.0  356.674032   91.294864    0.32000  375.377500  391.44000   \n",
       "LSTAT    506.0   12.653063    7.141062    1.73000    6.950000   11.36000   \n",
       "MEDV     506.0   22.532806    9.197104    5.00000   17.025000   21.20000   \n",
       "\n",
       "                75%       max  \n",
       "CRIM       3.677083   88.9762  \n",
       "ZN        12.500000  100.0000  \n",
       "INDUS     18.100000   27.7400  \n",
       "CHAS       0.000000    1.0000  \n",
       "NOX        0.624000    0.8710  \n",
       "RM         6.623500    8.7800  \n",
       "AGE       94.075000  100.0000  \n",
       "DIS        5.188425   12.1265  \n",
       "RAD       24.000000   24.0000  \n",
       "TAX      666.000000  711.0000  \n",
       "PTRATIO   20.200000   22.0000  \n",
       "B        396.225000  396.9000  \n",
       "LSTAT     16.955000   37.9700  \n",
       "MEDV      25.000000   50.0000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we use the describe method to understand general distribution of the data. T is used to swap rows and columns\n",
    "boston.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "#sns.distplot(boston['MEDV'], bins=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "X = boston.drop(\"MEDV\", axis=1)\n",
    "Y = boston[\"MEDV\"]\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train and test test. We use 80% of the sample for training and 20% for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n",
      "(404,)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's fit the model with default hyperparameters from sklearn to get a baseline idea of model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asimbanskota/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use mean absolute error and R squared to assess model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for baseline model is:\n",
      "---------------------------------------------\n",
      "mean absoulte error is 2.266078431372548\n",
      "R2 score is 0.8574924093945536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2=r2_score(y_test, y_pred)\n",
    "print(\"The model performance for baseline model is:\")\n",
    "print(\"---------------------------------------------\")\n",
    "print('mean absoulte error is {}'.format(mae))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With the default random forest regression hyperparameters the mean absoluate error for housing price prediction is 2.36 and R2 is 87%. Let's set up a dictionary with hyperparameters what we want to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'max_features': [2,3,5],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'n_estimators': [100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now create the instance of GridSearchCV with the hyperparameter grid. The parameter CV corresponds to the number of fold for cross validation. Once the GridSearchCV class is initialized, we call the fit method of the class and pass it the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:   21.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the parameters that return the highest accuracy which we do using the *best_estimator_*  attributes of the GridSearchCV object  as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "                      max_features=5, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=3, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "best_grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the best model returned from gridsearch to predict in the training set and calculate the model error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gridsearch = best_grid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for testing set from grid search\n",
      "--------------------------------------\n",
      "mean absoulte error is 2.064521797240613\n",
      "R2 score is 0.8890151457923472\n",
      "Improvement of 3.68%.\n"
     ]
    }
   ],
   "source": [
    "mae_gridsearch = mean_absolute_error(y_test, y_pred_gridsearch)\n",
    "r2_gridsearch=r2_score(y_test, y_pred_gridsearch)\n",
    "print(\"The model performance for testing set from grid search\")\n",
    "print(\"--------------------------------------\")\n",
    "print('mean absoulte error is {}'.format(mae_gridsearch))\n",
    "print('R2 score is {}'.format(r2_gridsearch))\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (r2_gridsearch- r2) / r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized Search for Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create  random grid for hyperparamter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "               'max_depth': list(np.linspace(10, 1200, 10, dtype = int)),\n",
    "               'n_estimators': list(np.linspace(100, 1200, 10, dtype = int))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   22.4s finished\n"
     ]
    }
   ],
   "source": [
    "random_grid_search = RandomizedSearchCV(estimator = rf, param_distributions = param_dist, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2,n_iter = 10)\n",
    "random_grid_search.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=142,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=222,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grid_randomsearch= random_grid_search.best_estimator_\n",
    "best_grid_randomsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for testing set from randomsearch search\n",
      "--------------------------------------\n",
      "mean absoulte error is 2.2317832538420803\n",
      "R2 score is 0.8558904773238419\n",
      "Improvement of -0.19%.\n"
     ]
    }
   ],
   "source": [
    "y_pred_randomsearch = best_grid_randomsearch.predict(x_test)\n",
    "mae_randomsearch = mean_absolute_error(y_test, y_pred_randomsearch)\n",
    "r2_randomsearch=r2_score(y_test, y_pred_randomsearch)\n",
    "print(\"The model performance for testing set from randomsearch search\")\n",
    "print(\"--------------------------------------\")\n",
    "print('mean absoulte error is {}'.format(mae_randomsearch))\n",
    "print('R2 score is {}'.format(r2_randomsearch))\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (r2_randomsearch- r2) / r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assigment: \n",
    "1. Change the hyperparameter values and check how the values in the best estimator changes and use it to predict for the test set.\n",
    "2. Use the sklearn best score function to check the cross validated score of the best estimator."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
